{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9acd7e5",
   "metadata": {},
   "source": [
    "## Extração de dados do portal do INMET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de2070",
   "metadata": {},
   "source": [
    "Downlaod de arquivos zip do site (Github - https://dkko.me/posts/coleta-tratamento-inmet-bdmep/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19acf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import httpx\n",
    "import datetime as dt\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def build_url(year):\n",
    "    return f'https://portal.inmet.gov.br/uploads/dadoshistoricos/{year}.zip'\n",
    "\n",
    "def parse_last_modified(last_modified: str) -> dt.datetime:\n",
    "    return dt.datetime.strptime(\n",
    "    \tlast_modified,\n",
    "    \t'%a, %d %b %Y %H:%M:%S %Z'\n",
    "    )\n",
    "\n",
    "def build_local_filename(year: int, last_modified: dt.datetime) -> str:\n",
    "    return f'inmet-bdmep_{year}_{last_modified:%Y%m%d}.zip'\n",
    "\n",
    "def download_year(\n",
    "    year: int,\n",
    "    destdirpath: Path,\n",
    "    blocksize: int = 2048,\n",
    ") -> None:\n",
    "\n",
    "    if not destdirpath.exists():\n",
    "        destdirpath.mkdir(parents=True)\n",
    "\n",
    "    url = build_url(year)\n",
    "\n",
    "    headers = httpx.head(url).headers\n",
    "    last_modified = parse_last_modified(headers['Last-Modified'])\n",
    "    file_size = int(headers.get('Content-Length', 0))\n",
    "\n",
    "    destfilename = build_local_filename(year, last_modified=last_modified)\n",
    "    destfilepath = destdirpath / destfilename\n",
    "    if destfilepath.exists():\n",
    "        return\n",
    "\n",
    "    with httpx.stream('GET', url) as r:\n",
    "        pb = tqdm(\n",
    "            desc=f'{year}',\n",
    "            dynamic_ncols=True,\n",
    "            leave=True,\n",
    "            total=file_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "        )\n",
    "        with open(destfilepath, 'wb') as f:\n",
    "            for data in r.iter_bytes(blocksize):\n",
    "                f.write(data)\n",
    "                pb.update(len(data))\n",
    "        pb.close()\n",
    "\n",
    "destdirpath = Path('C:/Users/z004wshk/OneDrive - Siemens Energy/Documents/BI Project')\n",
    "for year in range(2000, dt.datetime.now().year + 1):\n",
    "    download_year( year, destdirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4880b",
   "metadata": {},
   "source": [
    "Coleta de dados dos arquivos ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89963190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 27 arquivos ZIP para processar\n",
      "Processando arquivo: inmet-bdmep_2000_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2000_20200902.zip: ['2000/INMET_CO_DF_A001_BRASILIA_07-05-2000_A_31-12-2000.CSV', '2000/INMET_NE_BA_A401_SALVADOR_13-05-2000_A_31-12-2000.CSV', '2000/INMET_N_AM_A101_MANAUS_09-05-2000_A_31-12-2000.CSV']\n",
      "Encontrados 5 arquivos de dados em inmet-bdmep_2000_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2000_20200902.zip: 100%|██████████| 5/5 [00:00<00:00, 1256.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2001_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2001_20200902.zip: ['2001/INMET_CO_DF_A001_BRASILIA_01-01-2001_A_31-12-2001.CSV', '2001/INMET_CO_GO_A002_GOIANIA_29-05-2001_A_31-12-2001.CSV', '2001/INMET_CO_GO_A003_MORRINHOS_25-05-2001_A_31-12-2001.CSV']\n",
      "Encontrados 16 arquivos de dados em inmet-bdmep_2001_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2001_20200902.zip: 100%|██████████| 16/16 [00:00<00:00, 439.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2002_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2002_20200902.zip: ['2002/INMET_CO_DF_A001_BRASILIA_01-01-2002_A_31-12-2002.CSV', '2002/INMET_CO_GO_A002_GOIANIA_01-01-2002_A_31-12-2002.CSV', '2002/INMET_CO_GO_A003_MORRINHOS_01-01-2002_A_31-12-2002.CSV']\n",
      "Encontrados 33 arquivos de dados em inmet-bdmep_2002_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2002_20200902.zip: 100%|██████████| 33/33 [00:00<00:00, 529.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2003_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2003_20200902.zip: ['2003/INMET_CO_DF_A001_BRASILIA_01-01-2003_A_31-12-2003.CSV', '2003/INMET_CO_GO_A002_GOIANIA_01-01-2003_A_31-12-2003.CSV', '2003/INMET_CO_GO_A003_MORRINHOS_01-01-2003_A_31-12-2003.CSV']\n",
      "Encontrados 55 arquivos de dados em inmet-bdmep_2003_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2003_20200902.zip: 100%|██████████| 55/55 [00:00<00:00, 466.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2004_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2004_20200902.zip: ['2004/INMET_CO_DF_A001_BRASILIA_01-01-2004_A_31-12-2004.CSV', '2004/INMET_CO_GO_A002_GOIANIA_01-01-2004_A_31-12-2004.CSV', '2004/INMET_CO_GO_A003_MORRINHOS_01-01-2004_A_31-12-2004.CSV']\n",
      "Encontrados 62 arquivos de dados em inmet-bdmep_2004_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2004_20200902.zip: 100%|██████████| 62/62 [00:00<00:00, 477.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2005_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2005_20200902.zip: ['2005/INMET_CO_DF_A001_BRASILIA_01-01-2005_A_31-12-2005.CSV', '2005/INMET_CO_GO_A002_GOIANIA_01-01-2005_A_31-12-2005.CSV', '2005/INMET_CO_GO_A003_MORRINHOS_01-01-2005_A_31-12-2005.CSV']\n",
      "Encontrados 64 arquivos de dados em inmet-bdmep_2005_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2005_20200902.zip: 100%|██████████| 64/64 [00:00<00:00, 518.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2006_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2006_20200902.zip: ['2006/INMET_CO_DF_A001_BRASILIA_01-01-2006_A_31-12-2006.CSV', '2006/INMET_CO_GO_A002_GOIANIA_01-01-2006_A_31-12-2006.CSV', '2006/INMET_CO_GO_A003_MORRINHOS_01-01-2006_A_31-12-2006.CSV']\n",
      "Encontrados 154 arquivos de dados em inmet-bdmep_2006_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2006_20200902.zip: 100%|██████████| 154/154 [00:00<00:00, 322.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2007_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2007_20200902.zip: ['2007/INMET_CO_DF_A001_BRASILIA_01-01-2007_A_31-12-2007.CSV', '2007/INMET_CO_GO_A002_GOIANIA_01-01-2007_A_31-12-2007.CSV', '2007/INMET_CO_GO_A003_MORRINHOS_01-01-2007_A_31-12-2007.CSV']\n",
      "Encontrados 264 arquivos de dados em inmet-bdmep_2007_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2007_20200902.zip: 100%|██████████| 264/264 [00:00<00:00, 285.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2008_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2008_20200902.zip: ['2008/INMET_CO_DF_A001_BRASILIA_01-01-2008_A_31-12-2008.CSV', '2008/INMET_CO_DF_A045_AGUAS EMENDADAS_03-10-2008_A_31-12-2008.CSV', '2008/INMET_CO_GO_A002_GOIANIA_01-01-2008_A_31-12-2008.CSV']\n",
      "Encontrados 417 arquivos de dados em inmet-bdmep_2008_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2008_20200902.zip: 100%|██████████| 417/417 [00:01<00:00, 271.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2009_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2009_20200902.zip: ['2009/INMET_CO_DF_A001_BRASILIA_01-01-2009_A_31-12-2009.CSV', '2009/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2009_A_31-12-2009.CSV', '2009/INMET_CO_GO_A002_GOIANIA_01-01-2009_A_31-12-2009.CSV']\n",
      "Encontrados 434 arquivos de dados em inmet-bdmep_2009_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2009_20200902.zip: 100%|██████████| 434/434 [00:01<00:00, 228.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2010_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2010_20200902.zip: ['2010/INMET_CO_DF_A001_BRASILIA_01-01-2010_A_31-12-2010.CSV', '2010/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2010_A_31-12-2010.CSV', '2010/INMET_CO_GO_A002_GOIANIA_01-01-2010_A_31-12-2010.CSV']\n",
      "Encontrados 446 arquivos de dados em inmet-bdmep_2010_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2010_20200902.zip: 100%|██████████| 446/446 [00:02<00:00, 187.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2011_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2011_20200902.zip: ['2011/INMET_CO_DF_A001_BRASILIA_01-01-2011_A_31-12-2011.CSV', '2011/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2011_A_31-12-2011.CSV', '2011/INMET_CO_GO_A002_GOIANIA_01-01-2011_A_31-12-2011.CSV']\n",
      "Encontrados 456 arquivos de dados em inmet-bdmep_2011_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2011_20200902.zip: 100%|██████████| 456/456 [00:02<00:00, 162.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2012_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2012_20200902.zip: ['2012/INMET_CO_DF_A001_BRASILIA_01-01-2012_A_31-12-2012.CSV', '2012/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2012_A_31-12-2012.CSV', '2012/INMET_CO_GO_A002_GOIANIA_01-01-2012_A_31-12-2012.CSV']\n",
      "Encontrados 468 arquivos de dados em inmet-bdmep_2012_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2012_20200902.zip: 100%|██████████| 468/468 [00:03<00:00, 135.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2013_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2013_20200902.zip: ['2013/INMET_CO_DF_A001_BRASILIA_01-01-2013_A_31-12-2013.CSV', '2013/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2013_A_31-12-2013.CSV', '2013/INMET_CO_GO_A002_GOIANIA_01-01-2013_A_31-12-2013.CSV']\n",
      "Encontrados 473 arquivos de dados em inmet-bdmep_2013_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2013_20200902.zip: 100%|██████████| 473/473 [00:03<00:00, 125.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2014_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2014_20200902.zip: ['2014/INMET_CO_DF_A001_BRASILIA_01-01-2014_A_31-12-2014.CSV', '2014/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2014_A_31-12-2014.CSV', '2014/INMET_CO_DF_A046_GAMA (PONTE ALTA)_01-10-2014_A_31-12-2014.CSV']\n",
      "Encontrados 475 arquivos de dados em inmet-bdmep_2014_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2014_20200902.zip: 100%|██████████| 475/475 [00:04<00:00, 107.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2015_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2015_20200902.zip: ['2015/INMET_CO_DF_A001_BRASILIA_01-01-2015_A_31-12-2015.CSV', '2015/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2015_A_31-12-2015.CSV', '2015/INMET_CO_DF_A046_GAMA (PONTE ALTA)_01-01-2015_A_31-12-2015.CSV']\n",
      "Encontrados 484 arquivos de dados em inmet-bdmep_2015_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2015_20200902.zip: 100%|██████████| 484/484 [00:04<00:00, 100.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2016_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2016_20200902.zip: ['2016/INMET_CO_DF_A001_BRASILIA_01-01-2016_A_31-12-2016.CSV', '2016/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2016_A_31-12-2016.CSV', '2016/INMET_CO_DF_A046_GAMA (PONTE ALTA)_01-01-2016_A_31-12-2016.CSV']\n",
      "Encontrados 529 arquivos de dados em inmet-bdmep_2016_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2016_20200902.zip: 100%|██████████| 529/529 [00:05<00:00, 96.17it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2017_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2017_20200902.zip: ['2017/INMET_CO_DF_A001_BRASILIA_01-01-2017_A_31-12-2017.CSV', '2017/INMET_CO_DF_A042_BRAZLANDIA_19-07-2017_A_31-12-2017.CSV', '2017/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2017_A_31-12-2017.CSV']\n",
      "Encontrados 563 arquivos de dados em inmet-bdmep_2017_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2017_20200902.zip: 100%|██████████| 563/563 [00:07<00:00, 78.67it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2018_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2018_20200902.zip: ['2018/INMET_CO_DF_A001_BRASILIA_01-01-2018_A_31-12-2018.CSV', '2018/INMET_CO_DF_A042_BRAZLANDIA_01-01-2018_A_31-12-2018.CSV', '2018/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2018_A_31-12-2018.CSV']\n",
      "Encontrados 596 arquivos de dados em inmet-bdmep_2018_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2018_20200902.zip: 100%|██████████| 596/596 [00:08<00:00, 73.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2019_20200902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2019_20200902.zip: ['2019/INMET_CO_DF_A001_BRASILIA_01-01-2019_A_31-12-2019.CSV', '2019/INMET_CO_DF_A042_BRAZLANDIA_01-01-2019_A_31-12-2019.CSV', '2019/INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2019_A_31-12-2019.CSV']\n",
      "Encontrados 589 arquivos de dados em inmet-bdmep_2019_20200902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2019_20200902.zip: 100%|██████████| 589/589 [00:09<00:00, 61.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2020_20210104.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2020_20210104.zip: ['INMET_CO_DF_A001_BRASILIA_01-01-2020_A_31-12-2020.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2020_A_31-12-2020.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2020_A_31-12-2020.CSV']\n",
      "Encontrados 589 arquivos de dados em inmet-bdmep_2020_20210104.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2020_20210104.zip: 100%|██████████| 589/589 [00:10<00:00, 58.01it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2021_20220203.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2021_20220203.zip: ['INMET_CO_DF_A001_BRASILIA_01-01-2021_A_31-12-2021.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2021_A_31-12-2021.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2021_A_31-12-2021.CSV']\n",
      "Encontrados 588 arquivos de dados em inmet-bdmep_2021_20220203.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2021_20220203.zip: 100%|██████████| 588/588 [00:09<00:00, 61.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2022_20230105.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2022_20230105.zip: ['INMET_CO_DF_A001_BRASILIA_01-01-2022_A_31-12-2022.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2022_A_31-12-2022.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2022_A_31-12-2022.CSV']\n",
      "Encontrados 567 arquivos de dados em inmet-bdmep_2022_20230105.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2022_20230105.zip: 100%|██████████| 567/567 [00:10<00:00, 53.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2023_20240102.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2023_20240102.zip: ['INMET_CO_DF_A001_BRASILIA_01-01-2023_A_31-12-2023.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2023_A_31-12-2023.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2023_A_31-12-2023.CSV']\n",
      "Encontrados 567 arquivos de dados em inmet-bdmep_2023_20240102.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2023_20240102.zip: 100%|██████████| 567/567 [00:11<00:00, 48.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2024_20250102.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2024_20250102.zip: ['INMET_CO_DF_A001_BRASILIA_01-01-2024_A_31-12-2024.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2024_A_31-12-2024.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2024_A_31-12-2024.CSV']\n",
      "Encontrados 565 arquivos de dados em inmet-bdmep_2024_20250102.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2024_20250102.zip: 100%|██████████| 565/565 [00:12<00:00, 45.31it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2025_20250902.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2025_20250902.zip: ['INMET_CO_DF_A001_BRASILIA_01-01-2025_A_31-08-2025.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2025_A_31-08-2025.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2025_A_31-08-2025.CSV']\n",
      "Encontrados 563 arquivos de dados em inmet-bdmep_2025_20250902.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2025_20250902.zip: 100%|██████████| 563/563 [00:13<00:00, 42.02it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: inmet-bdmep_2025_20251104.zip\n",
      "Exemplos de arquivos em inmet-bdmep_2025_20251104.zip: ['INMET_CO_DF_A001_BRASILIA_01-01-2025_A_31-10-2025.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2025_A_31-10-2025.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2025_A_31-10-2025.CSV']\n",
      "Encontrados 571 arquivos de dados em inmet-bdmep_2025_20251104.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando inmet-bdmep_2025_20251104.zip: 100%|██████████| 571/571 [00:13<00:00, 42.42it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído. Total de registros: 5359087\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "import io\n",
    "import re\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def read_metadata(filepath: Path | zipfile.ZipExtFile) -> dict[str, str]:\n",
    "    if isinstance(filepath, zipfile.ZipExtFile):\n",
    "        f = io.TextIOWrapper(filepath, encoding='latin-1')\n",
    "    else:\n",
    "        f = open(filepath, 'r', encoding='latin-1')\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    _, regiao = next(reader)\n",
    "    _, uf = next(reader)\n",
    "    _, estacao = next(reader)\n",
    "    _, codigo_wmo = next(reader)\n",
    "    _, latitude = next(reader)\n",
    "    try:\n",
    "        latitude = float(latitude.replace(',', '.'))\n",
    "    except:\n",
    "        latitude = np.nan\n",
    "    _, longitude = next(reader)\n",
    "    try:\n",
    "        longitude = float(longitude.replace(',', '.'))\n",
    "    except:\n",
    "        longitude = np.nan\n",
    "    _, altitude = next(reader)\n",
    "    try:\n",
    "        altitude = float(altitude.replace(',', '.'))\n",
    "    except:\n",
    "        altitude = np.nan\n",
    "    _, data_fundacao = next(reader)\n",
    "    if re.match('[0-9]{4}-[0-9]{2}-[0-9]{2}', data_fundacao):\n",
    "        data_fundacao = dt.datetime.strptime(\n",
    "            data_fundacao,\n",
    "            '%Y-%m-%d',\n",
    "        )\n",
    "    elif re.match('[0-9]{2}/[0-9]{2}/[0-9]{2}', data_fundacao):\n",
    "        data_fundacao = dt.datetime.strptime(\n",
    "            data_fundacao,\n",
    "            '%d/%m/%y',\n",
    "        )\n",
    "    f.close()\n",
    "    return {\n",
    "        'regiao': regiao,\n",
    "        'uf': uf,\n",
    "        'estacao': estacao,\n",
    "        'codigo_wmo': codigo_wmo,\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'altitude': altitude,\n",
    "        'data_fundacao': data_fundacao,\n",
    "    }\n",
    "\n",
    "def columns_renamer(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    if re.match(r'data', name):\n",
    "        return 'data'\n",
    "    if re.match(r'hora', name):\n",
    "        return 'hora'\n",
    "    if re.match(r'precipita[çc][ãa]o', name):\n",
    "        return 'precipitacao'\n",
    "    if re.match(r'press[ãa]o atmosf[ée]rica ao n[íi]vel', name):\n",
    "        return 'pressao_atmosferica'\n",
    "    if re.match(r'press[ãa]o atmosf[ée]rica m[áa]x', name):\n",
    "        return 'pressao_atmosferica_maxima'\n",
    "    if re.match(r'press[ãa]o atmosf[ée]rica m[íi]n', name):\n",
    "        return 'pressao_atmosferica_minima'\n",
    "    if re.match(r'radia[çc][ãa]o', name):\n",
    "        return 'radiacao'\n",
    "    if re.match(r'temperatura do ar', name):\n",
    "        return 'temperatura_ar'\n",
    "    if re.match(r'temperatura do ponto de orvalho', name):\n",
    "        return 'temperatura_orvalho'\n",
    "    if re.match(r'temperatura m[áa]x', name):\n",
    "        return 'temperatura_maxima'\n",
    "    if re.match(r'temperatura m[íi]n', name):\n",
    "        return 'temperatura_minima'\n",
    "    if re.match(r'temperatura orvalho m[áa]x', name):\n",
    "        return 'temperatura_orvalho_maxima'\n",
    "    if re.match(r'temperatura orvalho m[íi]n', name):\n",
    "        return 'temperatura_orvalho_minima'\n",
    "    if re.match(r'umidade rel\\. m[áa]x', name):\n",
    "        return 'umidade_relativa_maxima'\n",
    "    if re.match(r'umidade rel\\. m[íi]n', name):\n",
    "        return 'umidade_relativa_minima'\n",
    "    if re.match(r'umidade relativa do ar', name):\n",
    "        return 'umidade_relativa'\n",
    "    if re.match(r'vento, dire[çc][ãa]o', name):\n",
    "        return 'vento_direcao'\n",
    "    if re.match(r'vento, rajada', name):\n",
    "        return 'vento_rajada'\n",
    "    if re.match(r'vento, velocidade', name):\n",
    "        return 'vento_velocidade'\n",
    "    # Retorna o nome original se não houver match\n",
    "    return name\n",
    "    \n",
    "def convert_dates(dates: pd.Series) -> pd.Series:  # Corrigido o tipo de retorno\n",
    "    dates = dates.str.replace('/', '-')\n",
    "    return dates\n",
    "\n",
    "\n",
    "def convert_hours(hours: pd.Series) -> pd.Series:  # Corrigido o tipo de retorno\n",
    "\n",
    "    def fix_hour_string(hour: str) -> str:\n",
    "        if pd.isna(hour):  # Verifica se é NaN\n",
    "            return hour\n",
    "        if re.match(r'^\\d{2}\\:\\d{2}$', hour):\n",
    "            return hour\n",
    "        else:\n",
    "            return hour[:2] + ':00'\n",
    "\n",
    "    hours = hours.apply(fix_hour_string)\n",
    "    return hours\n",
    "\n",
    "def read_data(filepath: zipfile.ZipExtFile) -> pd.DataFrame:  # Corrigido o tipo do parâmetro\n",
    "    d = pd.read_csv(\n",
    "        filepath,\n",
    "        sep=';',\n",
    "        decimal=',',\n",
    "        na_values='-9999',\n",
    "        encoding='latin-1',\n",
    "        skiprows=8,\n",
    "        usecols=range(19),\n",
    "    )\n",
    "    d = d.rename(columns=columns_renamer)\n",
    "\n",
    "    # Remove empty rows\n",
    "    empty_columns = [\n",
    "        'precipitacao',\n",
    "        'pressao_atmosferica',\n",
    "        'pressao_atmosferica_maxima',\n",
    "        'pressao_atmosferica_minima',\n",
    "        'radiacao',\n",
    "        'temperatura_ar',\n",
    "        'temperatura_orvalho',\n",
    "        'temperatura_maxima',\n",
    "        'temperatura_minima',\n",
    "        'temperatura_orvalho_maxima',\n",
    "        'temperatura_orvalho_minima',\n",
    "        'umidade_relativa_maxima',\n",
    "        'umidade_relativa_minima',\n",
    "        'umidade_relativa',\n",
    "        'vento_direcao',\n",
    "        'vento_rajada',\n",
    "        'vento_velocidade',\n",
    "    ]\n",
    "    empty_rows = d[empty_columns].isnull().all(axis=1)\n",
    "    d = d.loc[~empty_rows]\n",
    "\n",
    "    # Corrigido: aplicar as conversões nas colunas corretas\n",
    "    d['data'] = convert_dates(d['data'])\n",
    "    d['hora'] = convert_hours(d['hora'])\n",
    "\n",
    "    return d\n",
    "\n",
    "def read_zipfiles(destdirpath: Path) -> pd.DataFrame:\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    zip_files = list(destdirpath.glob('*.zip'))\n",
    "    \n",
    "    if not zip_files:\n",
    "        print(f'Nenhum arquivo .zip encontrado em {destdirpath}')\n",
    "        return data\n",
    "    \n",
    "    print(f'Encontrados {len(zip_files)} arquivos ZIP para processar')\n",
    "    i=0\n",
    "    for filepath in zip_files:\n",
    "        print(f'Processando arquivo: {filepath.name}')\n",
    "        try:\n",
    "            with zipfile.ZipFile(filepath) as z:\n",
    "                all_files = [zf for zf in z.infolist() if not zf.is_dir()]\n",
    "                \n",
    "                if not all_files:\n",
    "                    print(f'Nenhum arquivo encontrado em {filepath.name}')\n",
    "                    continue\n",
    "                \n",
    "                print(f'Exemplos de arquivos em {filepath.name}: {[f.filename for f in all_files[:3]]}')\n",
    "                \n",
    "                data_files = [zf for zf in all_files if \n",
    "                             zf.filename.lower().endswith(('.csv', '.txt')) or \n",
    "                             (not '.' in zf.filename.split('/')[-1] and zf.file_size > 100)]\n",
    "                \n",
    "                if not data_files:\n",
    "                    data_files = [zf for zf in all_files if zf.file_size > 100]\n",
    "                    print(f'Tentando processar {len(data_files)} arquivos de dados em {filepath.name}')\n",
    "                else:\n",
    "                    print(f'Encontrados {len(data_files)} arquivos de dados em {filepath.name}')\n",
    "                \n",
    "                for zf in tqdm(data_files, desc=f'Processando {filepath.name}'):\n",
    "                    try:\n",
    "                        meta = read_metadata(z.open(zf.filename))\n",
    "\n",
    "                        if meta['uf']!='SP':\n",
    "                            continue\n",
    "\n",
    "                        d = read_data(z.open(zf.filename))\n",
    "                        \n",
    "                        if d.empty:\n",
    "                            continue\n",
    "                        \n",
    "                        d = d.assign(**meta)\n",
    "                        data = pd.concat([data, d], ignore_index=True)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f'Erro ao processar arquivo {zf.filename}: {e}')\n",
    "                        continue\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f'Erro ao abrir arquivo zip {filepath.name}: {e}')\n",
    "            continue\n",
    "\n",
    "    print(f'Processamento concluído. Total de registros: {len(data)}')\n",
    "    \n",
    "    if 'data' in data.columns and 'hora' in data.columns:\n",
    "        try:\n",
    "            data['datetime'] = pd.to_datetime(data['data'] + ' ' + data['hora'], errors='coerce')\n",
    "        except:\n",
    "            print('Não foi possível criar coluna datetime')\n",
    "    \n",
    "    return data\n",
    "\n",
    "destdirpath = Path('C:/Users/z004wshk/OneDrive - Siemens Energy/Documents/BI Project')\n",
    "df = read_zipfiles(destdirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f18134",
   "metadata": {},
   "source": [
    "# Tratamento de dados metereológicos de algumas cidades de SP (dados tem limitações)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04222533",
   "metadata": {},
   "source": [
    "Configuração de datatype e agregação para análise por dia (média ou soma por dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data']=df['data'].astype('datetime64[ns]')\n",
    "df['regiao']=df['regiao'].astype('string')\n",
    "df['uf']=df['uf'].astype('string')\n",
    "df['estacao']=df['estacao'].astype('string')\n",
    "df['codigo_wmo']=df['codigo_wmo'].astype('string')\n",
    "df = (df.drop(columns=['hora', 'data_fundacao', 'datetime', 'pressao_atmosferica_maxima', 'pressao_atmosferica_minima',\n",
    "                                'temperatura_orvalho_maxima', 'temperatura_orvalho_minima']))\n",
    "\n",
    "agg_dict={}\n",
    "for col in df.columns:\n",
    "    if col=='regiao' or col=='uf' or col=='codigo_wmo':\n",
    "        agg_dict[col]='unique'\n",
    "    elif col=='precipitacao':\n",
    "        agg_dict[col]='sum'\n",
    "    elif col!='estacao' and col!='data':\n",
    "        agg_dict[col]='mean'\n",
    "\n",
    "\n",
    "df = df.groupby(['estacao','data']).agg(agg_dict)\n",
    "df.reset_index().sort_values(['estacao', 'data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eefa54",
   "metadata": {},
   "source": [
    "Implementação das métricas **Íncide de Calor** (Heat Index), **Sensação térmica** (Wind Chill Index - WCI) e **Índice de Umidade** (Humidex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_index_celsius(T, R):\n",
    "    # com T temperatura do ar e R umidade relativa\n",
    "    c1 = -8.78469475556\n",
    "    c2 = 1.61139411\n",
    "    c3 = 2.33854883889\n",
    "    c4 = -0.14611605\n",
    "    c5 = -0.012308094\n",
    "    c6 = -0.0164248277778\n",
    "    c7 = 2.211732e-3\n",
    "    c8 = 7.2546e-4\n",
    "    c9 = -3.582e-6\n",
    "    \n",
    "    HI = (c1 + c2*T + c3*R + c4*T*R + c5*T**2 + c6*R**2 + \n",
    "          c7*T**2*R + c8*T*R**2 + c9*T**2*R**2)\n",
    "    \n",
    "    return HI\n",
    "import math\n",
    "\n",
    "def wci(V, T):\n",
    "    # com V velocidade do vento e T temperatura do ar\n",
    "    return (10 * math.sqrt(V) - V + 10.5) * (33 - T)\n",
    "\n",
    "def humidex(T, T_o):\n",
    "    # com T temperatura do ar e T_o temperatura de orvalho\n",
    "    T_o_K = T_o + 273.15\n",
    "    e = 6.11 * math.exp(5417.7530 * (1/273.16 - 1/T_o_K))\n",
    "    humidex = T + 0.5555 * (e - 10.0)\n",
    "    return humidex\n",
    "\n",
    "df['Heat Index'] = df.apply(lambda x: heat_index_celsius(x['temperatura_ar'], x['umidade_relativa']), axis=1)\n",
    "df['WCI'] = df.apply(lambda x: wci(x['vento_velocidade'], x['temperatura_ar']), axis=1)\n",
    "df['Humidex'] = df.apply(lambda x: humidex(x['temperatura_ar'], x['temperatura_orvalho']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d958660",
   "metadata": {},
   "source": [
    "Download da base de dados para futuras análises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('Data.xlsx', 'Database')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
